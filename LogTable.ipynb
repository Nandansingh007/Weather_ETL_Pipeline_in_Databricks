{"cells":[{"cell_type":"markdown","source":["#### Importing necessary Libraries"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"ddf87123-a975-483c-95ef-1395c06df7b0","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import requests\nimport uuid\nfrom datetime import datetime\nfrom pyspark.sql.functions import col, udf, explode\nfrom pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, TimestampType, ArrayType\nfrom pyspark.sql.functions import from_unixtime"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"6478783b-2a79-4bcc-b121-9a8b77b128c2","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Creating Log Table"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"3ea7a464-9dbb-441d-b329-91db27387374","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%sql \n\nCREATE TABLE IF NOT EXISTS weather_log_table ( \n      id STRING,\n      load_type STRING,\n      table_name STRING,\n      process_start_time TIMESTAMP,\n      process_end_time TIMESTAMP,\n      status STRING,\n      comments STRING,\n      start_date_time TIMESTAMP,\n      end_date_time TIMESTAMP,\n      created_on TIMESTAMP,\n      created_by STRING\n    )\n    \n    "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000,"implicitDf":true},"nuid":"3b433114-1ec3-4c11-b3fe-904dd476abda","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n","  .table-result-container {\n","    max-height: 300px;\n","    overflow: auto;\n","  }\n","  table, th, td {\n","    border: 1px solid black;\n","    border-collapse: collapse;\n","  }\n","  th, td {\n","    padding: 5px;\n","  }\n","  th {\n","    text-align: left;\n","  }\n","</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Decorator Function To Update Log Table"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"ef1f78a9-4c3c-44fe-9a5b-80cef8f61975","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def keep_log(func):\n    def wrapper(*args, **kwargs):\n        \n        import uuid\n        from datetime import datetime\n        from pyspark.sql.functions import col, udf\n        from pyspark.sql.types import TimestampType\n\n        id = str(uuid.uuid4())\n        load_type = args[0]\n        table_name = args[1]\n        process_start_dt = datetime.now()\n        name = 'Nandan Singh'\n        status = 'EXTRACTING'\n\n        query = f\"insert into weather_log_table (id, load_type, table_name, process_start_time, status, created_on, created_by)\\\n            values ('{id}', '{load_type}', '{table_name}', '{process_start_dt}', '{status}', '{process_start_dt}', '{name}')\"\n        spark.sql(query)\n        \n        try:\n            df, start, end = func(*args[2:], **kwargs)\n            status = 'COMPLETED'\n        except Exception as e:\n            status = 'ERROR'\n            process_end_dt = datetime.now()\n            query = f\"update weather_log_table \\\n                        set process_end_time = '{process_end_dt}', status='{status}', comments='{e}',\\\n                        where id='{id}'\"\n            spark.sql(query)\n            dbutils.notebook.exit(1)\n        \n        \n        \n        udf_id = udf(lambda : id)\n        udf_created_on = udf(lambda : process_start_dt, TimestampType())\n        udf_created_by = udf(lambda : name)\n        \n        df = df.withColumn('load_run_id', udf_id())\n        df = df.withColumn('created_on', udf_created_on())\n        df = df.withColumn('created_by', udf_created_by())\n        \n        df.write.format('delta').mode('append').saveAsTable(table_name)\n        \n        process_end_dt = datetime.now()\n        query = f\"update weather_log_table \\\n                    set process_end_time = '{process_end_dt}', status='{status}', start_date_time='{start}',\\\n                        end_date_time='{end}'\\\n                    where id='{id}'\"\n        spark.sql(query)\n        \n        return df\n    \n    return wrapper"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"9aed0e90-54c9-40ea-af7b-596c2269c0af","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"LogTable","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4,"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":3367044641153510,"dataframes":["_sqldf"]}},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
